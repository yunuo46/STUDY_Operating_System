# **프로세스가 무엇인가요?**

프로세스(Process)는 컴퓨터에서 **실행 중인 프로그램**을 의미합니다. 디스크에 저장된 정적인 프로그램 코드와 달리, 프로세스는 운영체제로부터 메모리, CPU 시간 등 자원을 할당받아 실행되는 동적인 존재입니다. 각 프로세스는 독립적인 메모리 공간을 가지며, 다른 프로세스와 분리되어 실행됩니다.

## 프로그램과 프로세스, 스레드의 차이에 대해 설명해 주세요.

- **프로그램 (Program)**: 특정 작업을 수행하기 위한 코드의 덩어리로, 디스크에 저장된 **정적인 파일 상태**이다. 생명이 없다.
- **프로세스 (Process)**: 프로그램이 실행되어 메모리에 올라온 **동적인 상태**이다. 운영체제로부터 독립된 메모리 영역(Code, Data, Stack, Heap)을 할당받는 **자원 할당의 기본 단위**이다. 각 프로세스는 최소 하나 이상의 스레드를 가진다.
- **스레드 (Thread)**: 프로세스 내에서 실행되는 **실행 흐름의 기본 단위**이다. 스레드는 프로세스로부터 할당받은 자원 중 **Code, Data, Heap 영역을 다른 스레드와 공유**하고, 자신만의 **Stack 영역과 PC 레지스터** 값을 가진다.

## PCB가 무엇인가요?

  PCB(프로세스 제어 블록)는 **운영체제가 특정 프로세스를 관리하기 위해 필요한 모든 정보를 담고 있는 자료구조**이다. TCB(Task Control Block)라고도 불린다. 프로세스가 생성될 때마다 고유의 PCB가 생성되며, 이 PCB는 커널 메모리 영역에 저장된다.
  - **주요 정보**: 프로세스 식별자(PID), 프로세스 상태(생성, 준비, 실행 등), 프로그램 카운터(PC), CPU 레지스터 값, 스케줄링 정보(우선순위 등), 메모리 관리 정보, 입출력 상태 정보 등이 포함된다.

## 그렇다면, 스레드는 PCB를 갖고 있을까요?

- 스레드는 PCB를 가지고있지 않다. 스레드는 PCB를 공유하며 자원들을 접근한다. 이떄 공유자원을 잘 사용해야하기에 공유락, 베타락 등 자원 관리 방법이 나오게 된 것.
- 대신에 TCB를 가지고있다. 스레드 컨트롤 블록으로 그 안에는 스택, 레지스터, 상태 정보가 들어있다.
- 스레드는 Stack을 별도로 가지고있다.

## 리눅스에서, 프로세스와 스레드는 각각 어떻게 생성될까요?

`clone()`은 새 프로세스(또는 스레드)를 생성할 때 부모 프로세스의 자원을 얼마나 공유할지, 그리고 무엇을 공유할지를 제어하는 다양한 플래그를 인자로 받습니다.

- **프로세스 생성을 위한 `fork()`**:
  - `fork()`는 `clone()`을 호출할 때 **부모의 자원을 공유하지 않도록** 플래그를 설정합니다.
  - 예를 들어, `CLONE_VM`, `CLONE_FS`, `CLONE_FILES` 같은 플래그를 **모두 0으로** 설정합니다.
  - 이렇게 하면 커널은 부모 프로세스의 메모리 공간, 파일 시스템 상태, 파일 디스크립터 테이블 등을 **모두 복제**하여 완전히 독립적인 자식 프로세스를 만듭니다.
- **스레드 생성을 위한 `pthread_create()`**:
   - `pthread_create()`는 `clone()`을 호출할 때 **부모의 자원을 공유하도록** 플래그를 설정합니다.
   - 예를 들어, `CLONE_VM`, `CLONE_FS`, `CLONE_FILES` 같은 플래그를 **1로** 설정합니다.
   - `CLONE_VM` 플래그는 부모와 자식이 **메모리 공간(힙, 데이터, 코드 영역)**을 공유하게 합니다.
   - `CLONE_FS` 플래그는 파일 시스템 정보를 공유하게 합니다.
   - `CLONE_FILES` 플래그는 열린 파일 디스크립터들을 공유하게 합니다.

## 자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?
- **좀비 프로세스 (Zombie Process)**: 자식 프로세스가 종료되었으나 부모 프로세스가 자식의 종료 상태를 회수(`wait()`)하지 않은 상태이다. 이 경우 자식 프로세스는 PCB 정보가 커널에 남아있는 **'좀비'** 상태가 된다. 부모가 `wait()`를 호출하면 비로소 완전히 소멸한다. 좀비 프로세스가 너무 많아지면 시스템 자원(PID)이 고갈될 수 있다.
- **고아 프로세스 (Orphan Process)**: 부모 프로세스가 자식보다 먼저 종료된 경우이다. 이 경우 남겨진 자식 프로세스는 '고아'가 되며, 즉시 모든 프로세스의 시조인 **`init` 프로세스(PID 1번)가 새로운 부모가 되어** 자식의 종료를 책임지고 회수해준다.

## 리눅스에서, 데몬프로세스에 대해 설명해 주세요.

  데몬 프로세스는 **사용자가 직접 제어하지 않고, 시스템이 부팅될 때 자동으로 실행되어 백그라운드에서 계속 실행되는 프로세스**를 말한다. 주로 네트워크 요청 처리, 하드웨어 관리, 로그 기록 등 시스템의 핵심적인 서비스를 제공하는 역할을 한다. 데몬 프로세스는 터미널 제어(`tty`)를 갖지 않으며, 보통 이름 끝에 `d`(daemon)가 붙는다(예: `sshd`, `httpd`).

## 리눅스는 프로세스가 일종의 트리를 형성하고 있습니다. 이 트리의 루트 노드에 위치하는 프로세스에 대해 설명해 주세요.
- 리눅스 프로세스 트리의 최상위 루트 노드에는 **`init` 프로세스**가 위치한다.
    - `init` 프로세스는 부팅 과정에서 커널이 가장 마지막에 실행하는 프로세스로, **PID(프로세스 ID) 1번**을 할당받는다.
    - 이 프로세스는 시스템의 모든 다른 프로세스의 **최초 부모 프로세스** 역할을 한다.
    - 또한 위에서 설명한 것처럼 부모를 잃은 **고아 프로세스들을 입양하여** 관리하는 중요한 책임을 맡는다.
    - 최신 리눅스 시스템에서는 `init`의 역할을 `systemd`라는 프로세스가 대체하여 수행하는 경우가 많다.
    - `systemd`는 `init`이 담당했던 역할 외에도, 서비스의 병렬 실행, 동적인 의존성 관리 등 더 많은 기능을 제공하여 부팅 속도를 향상시키고 시스템 관리를 효율적으로 만든다.

---
# **프로세스 주소공간에 대해 설명해 주세요.**

프로세스 주소 공간은 운영체제가 각 프로세스마다 독립적으로 제공하는 **논리적인 메모리 공간**을 말합니다. 운영체제는 다중 프로세스가 동시에 실행될 수 있도록 **메모리 보호와 독립성**을 보장해야 합니다. 이를 위해 각 프로세스는 자신만의 주소 공간을 가진 것처럼 보이게 합니다. 실제 물리 메모리는 공유되지만, **가상 메모리** 기법을 통해 **프로세스마다 분리된 메모리 영역**을 사용하는 것처럼 운영됩니다.

## 초기화 하지 않은 변수들은 어디에 저장될까요?

  **BSS 영역**에 저장된다. Data 영역은 초기값을 가지므로 그 값을 실행 파일에 저장해야 하지만, BSS 영역의 변수들은 어차피 0으로 초기화될 것이므로 실행 파일에 공간을 차지할 필요가 없다. 따라서 실행 파일의 크기를 줄이기 위해 별도의 BSS 영역으로 구분하여 관리한다.

  자바에서는 변수들이 JVM의 메모리 영역에 저장되기 때문에, 초기화 하지 않은 변수를 허용하지 않는다.

## 일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요? 그렇지 않다면, 그 크기는 언제 결정될까요?

- **그렇지 않다.** 그림에서 크게 그려지는 것은 가상 주소 공간의 '영역'을 나타낼 뿐, 처음부터 물리 메모리를 크게 차지하는 것은 아니다.
    - **스택 (Stack)**: 프로세스가 시작될 때 컴파일러에 의해 **일정한 크기(보통 수 MB)로 미리 할당**된다. 이 크기를 넘어서면 스택 오버플로우가 발생한다.
    - **힙 (Heap)**: 처음에는 매우 작은 크기로 할당되며, 프로그램 실행 중 `malloc()`, `new` 등의 요청이 있을 때마다 **필요한 만큼 동적으로 커진다.**

## Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?

  **스택이 훨씬 빠르다.** 스택은 단순히 스택 포인터(SP) 레지스터를 이동시키는 매우 빠른 CPU 명령어로 메모리를 할당하고 해제한다. 반면, 힙은 사용 가능한 메모리 블록을 찾고(때로는 복잡한 알고리즘 사용), 할당 정보를 기록하고, 해제 시에도 병합 등의 추가 작업이 필요하여 상대적으로 느리다.

## 다음과 같이 공간을 분할하는 이유가 있을까요?

프로세스 주소공간을 여러 영역으로 분할하는 가장 큰 이유는 **메모리 관리의 효율성, 보안, 그리고 재사용성**을 확보하기 위해서입니다.

1. **메모리 효율성**: 크기가 고정된 코드와 변수들을 분리하고, 동적으로 크기가 변하는 스택과 힙을 따로 관리하면 메모리를 낭비하지 않습니다.
2. **보안**: 각 영역에 읽기, 쓰기, 실행 권한을 다르게 부여하여 코드 영역에 대한 악의적인 쓰기 공격 등을 막을 수 있습니다.
3. **재사용성**: 여러 프로세스가 동일한 프로그램을 실행할 때, 코드 영역을 공유하여 메모리를 절약할 수 있습니다.

## 스레드의 주소공간은 어떻게 구성되어 있을까요?

  스레드는 프로세스의 **메모리 주소공간을 공유**합니다. 따라서 같은 코드, 데이터, 힙 영역을 사용합니다. 하지만, 각 스레드는 독립적인 함수 호출 정보를 가져야 하므로 **스택(Stack) 영역은 스레드마다 독립적**으로 가집니다

##  "스택"영역과 "힙"영역은 정말 자료구조의 스택/힙과 연관이 있는 걸까요? 만약 그렇다면, 각 주소공간의 동작과정과 연계해서 설명해 주세요.

### 스택 영역과 자료구조 스택의 관계

- 프로세스의 **스택 영역**은 함수 호출 시 **후입선출** 원리로 관리됩니다.
- 자료구조에서의 **스택**과 동작 방식이 같기 때문에 이름이 붙은 거예요.
- 함수 호출 시:
  1. 지역 변수, 매개변수, 리턴 주소 등이 스택 프레임에 push
  2. 함수가 끝나면 pop 되면서 자동 회수
- 그래서 **프로세스의 스택 = 자료구조 스택을 OS/CPU가 하드웨어적으로 지원해주는 메모리 영역**이라고 이해할 수 있습니다.

### 힙 영역과 자료구조 힙의 관계

- 프로세스의 **힙 영역** 은 동적 메모리를 저장하는 공간 (`malloc`, `new`, `free`)
- 자료구조에서의 **힙** 은 **완전이진트리 기반의 우선순위 큐**
- **즉, 이름만 같을 뿐 직접적인 연관은 없습니다.**
- 왜 이름이 "힙"이냐?
    - 옛날 할당기가 메모리를 자유롭게 이리저리 쌓아두는 덩어리라는 표현에서 나온 것입니다.
    - 자료구조의 heap과는 전혀 다르고, 단순히 "무더기"라는 의미에 가깝습니다.

##  IPC의 Shared Memory 기법은 프로세스 주소공간의 어디에 들어가나요? 그런 이유가 있을까요?

  IPC의 **Shared Memory(공유 메모리) 기법**은 프로세스 주소공간의 **힙(Heap) 영역**에 할당됩니다. 프로세스는 원래 독립적인 메모리 공간을 가지므로 서로 접근할 수 없습니다. 공유 메모리는 커널이 특정 메모리 영역을 두 프로세스 모두의 주소공간에 **매핑**해 주는 방식으로 동작합니다. 이렇게 매핑된 공유 메모리는 동적으로 할당되는 힙 영역에 위치하여, 두 프로세스가 서로의 메모리처럼 자유롭게 접근하여 데이터를 주고받을 수 있게 됩니다.

## 스택과 힙영역의 크기는 언제 결정되나요? 프로그램 개발자가 아닌, 사용자가 이 공간의 크기를 수정할 수 있나요?
- **스택 크기**: 초기 크기는 컴파일러와 운영체제의 기본값에 따라 결정됩니다. 사용자는 **`ulimit -s`** 명령어를 통해 최대 스택 크기를 수정할 수 있습니다.
- **힙 크기**: 프로그램 실행 중 `malloc` 같은 함수 호출에 따라 **동적으로 확장**됩니다. 사용자는 **`ulimit -d`** 명령어를 통해 데이터 영역의 최대 크기를 제한하여 힙 크기에 간접적으로 영향을 줄 수 있습니다.

# **단기, 중기, 장기 스케쥴러에 대해 설명해 주세요.**

- **장기 스케줄러(Long-Term Scheduler)**: **어떤 프로그램을 프로세스로 만들지** 결정합니다. 보조 기억 장치(하드디스크)에 있는 프로그램 중 일부를 선택해 메모리에 적재하는 역할을 합니다.
- **중기 스케줄러(Medium-Term Scheduler)**: **메모리 효율**을 관리합니다. 메모리가 부족할 때 일부 프로세스를 보조 기억 장치로 쫓아냅니다(스왑 아웃).
- **단기 스케줄러(Short-Term Scheduler)**: **다음 프로세스에게 CPU를 할당**하는 역할을 합니다. 실행 준비 상태에 있는 프로세스들 중에서 가장 먼저 실행될 프로세스를 결정하며, CPU 스케줄러라고도 불립니다.

## 현대 OS에는 단기, 중기, 장기 스케쥴러를 모두 사용하고 있나요?

  현대 운영체제는 단기 스케줄러와 중기 스케줄러를 주로 사용합니다. 장기 스케줄러는 과거의 배치(Batch) 시스템에서 사용되었고, 현대 OS는 대부분의 작업을 메모리에 바로 올려 실행 준비 상태로 만듭니다.

## 프로세스의 스케쥴링 상태에 대해 설명해 주세요.
- **생성(New)**: 프로세스가 생성되어 메모리에 적재되는 초기 상태입니다.
- **준비(Ready)**: CPU를 할당받기 위해 대기하는 상태입니다.
- **실행(Running)**: CPU를 할당받아 명령어를 실행하고 있는 상태입니다.
- **대기(Waiting)**: 파일 입출력 등 어떤 사건이 발생하기를 기다리는 상태입니다.
- **종료(Terminated)**: 모든 실행을 마치고 시스템에서 제거되는 상태입니다.
## preemptive/non-preemptive 에서 존재할 수 없는 상태가 있을까요?

  Non-preemptive(비선점) 스케줄링에서는 실행(Running) 상태에서 준비(Ready) 상태로 돌아가는 전이가 존재하지 않습니다. CPU를 할당받은 프로세스는 스스로 대기 상태로 가거나, 실행을 모두 마칠 때까지 CPU를 독점합니다. 반면, Preemptive(선점) 스케줄링에서는 실행 상태에서 준비 상태로 강제로 전환될 수 있습니다.

## Memory가 부족할 경우, Process는 어떠한 상태로 변화할까요?

  메모리가 부족해지면, 프로세스는 중기 스케줄러에 의해 **'스왑 아웃(Swapped Out)'**되어 '정지(Suspended)' 상태로 바뀝니다. 스왑 아웃된 프로세스는 메모리에서 보조 기억 장치로 옮겨지며, 메모리 여유 공간이 다시 확보될 때까지 정지 상태로 머무릅니다.
